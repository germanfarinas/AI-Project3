{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_project3_largedataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "lufOj9fUDEIk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "zoJ2nKs5AADn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Demo AI project 3 Large dataset (~20000 training samples)\n",
        "<a href=\"https://colab.research.google.com/github/germanfarinas/AI-Project3/blob/master/AI_project3_largedataset.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "metadata": {
        "id": "JB6kZ749eVuU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import os   # to save the checkpoint\n",
        "import pandas as pd\n",
        "#sess = tf.InteractiveSession()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "psrHVWJF9Hwi",
        "colab_type": "code",
        "outputId": "694c5635-91d5-47d8-ee8e-253806c5652b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = r\"/content/gdrive/My Drive/Colab Notebooks/Data\"  #change dir to your project folder\n",
        "os.chdir(root_path)\n",
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/Data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "s_lbbOFsHZai",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Example 2 Letter Recognition Dataset"
      ]
    },
    {
      "metadata": {
        "id": "yBDtFHjz98yr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Prepare the data\n",
        "def read_dataset():\n",
        "  file = \"letter-recognition.data\"\n",
        "  data = pd.read_csv(file,delim_whitespace=False,header=-1)\n",
        "  data = np.array(data)\n",
        "  np.random.shuffle(data)\n",
        "  # #Training Data\n",
        "  ratio = 0.8 # train/Total\n",
        "  training_data = data[0:int(len(data)*ratio)]\n",
        "  print(training_data)\n",
        "  testing_data = data[int(len(data)*ratio):len(data)]\n",
        "  x_train = training_data[:, 1:]\n",
        "  x_train = x_train.astype(float)\n",
        "  y_train = training_data[:, 0]\n",
        "  #y_train = y_train.T[0]=='g'\n",
        "  #y_train = y_train.astype(int)\n",
        "  #Testing Data\n",
        "  x_test = testing_data[:, 1:]\n",
        "  x_test = x_test.astype(float)\n",
        "  y_test = testing_data[:, 0]\n",
        "  #y_test = y_test.T[0]=='g'\n",
        "  #y_test = y_test.astype(int)\n",
        "  return x_train,y_train,x_test,y_test\n",
        "\n",
        "def create_model(N_input,N_hidden,N_output):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(N_hidden,input_dim = N_input, activation='relu')) \n",
        "  model.add(tf.keras.layers.Dense(N_output, activation='sigmoid'))\n",
        "  \n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='sgd',\n",
        "             metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vHVo1YPlKP7o",
        "colab_type": "code",
        "outputId": "f3619b18-52fd-4459-f3d8-85052ec425d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "x_train,y_train_,x_test,y_test_ = read_dataset()\n",
        "print('Training data size:' + str(x_train.shape))\n",
        "print('Training labels size: ' + str(y_train_.shape))\n",
        "\n",
        "print('Test data size: ' + str(x_test.shape))\n",
        "print('Test label size: ' + str(y_test_.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['R' 6 9 ... 7 7 11]\n",
            " ['L' 2 5 ... 7 3 8]\n",
            " ['M' 5 9 ... 5 2 8]\n",
            " ...\n",
            " ['H' 3 6 ... 8 3 6]\n",
            " ['T' 2 7 ... 8 0 8]\n",
            " ['P' 6 6 ... 10 4 8]]\n",
            "Training data size:(16000, 16)\n",
            "Training labels size: (16000,)\n",
            "Test data size: (4000, 16)\n",
            "Test label size: (4000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WKGEtJ3iMX5a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Convert labels to one hot"
      ]
    },
    {
      "metadata": {
        "id": "G2jXG22wLvAb",
        "colab_type": "code",
        "outputId": "bc34245a-e1e2-4089-f56b-666b6ff710d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "# change y [1D] to Y [2D] sparse array coding class\n",
        "n_examples = len(y_train_)\n",
        "labels = np.unique(y_train_)\n",
        "y_train = np.zeros((n_examples, len(labels)))\n",
        "for ix_label in range(len(labels)):\n",
        "    # Find examples with with a Label = lables(ix_label)\n",
        "    ix_tmp = np.where(y_train_ == labels[ix_label])[0]\n",
        "    y_train[ix_tmp, ix_label] = 1\n",
        "print(labels)\n",
        "print(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R'\n",
            " 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z']\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O0ObFT0aM7Qf",
        "colab_type": "code",
        "outputId": "54385283-4f47-42c3-e0d4-5f38d5d49973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "# change y [1D] to Y [2D] sparse array coding class\n",
        "n_examples = len(y_test_)\n",
        "labels = np.unique(y_test_)\n",
        "y_test = np.zeros((n_examples, len(labels)))\n",
        "for ix_label in range(len(labels)):\n",
        "    # Find examples with with a Label = lables(ix_label)\n",
        "    ix_tmp = np.where(y_test_ == labels[ix_label])[0]\n",
        "    y_test[ix_tmp, ix_label] = 1\n",
        "print(labels)\n",
        "print(y_test)\n",
        "print(len(labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R'\n",
            " 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z']\n",
            "[[0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vDAjiDJqQA_S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create the model"
      ]
    },
    {
      "metadata": {
        "id": "DQ0_0_buPTxf",
        "colab_type": "code",
        "outputId": "696cd7dd-4e56-4058-895a-8be732d92251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "model = create_model(16,300,26)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 300)               5100      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 26)                7826      \n",
            "=================================================================\n",
            "Total params: 12,926\n",
            "Trainable params: 12,926\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wwGhEPTmRGDL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the classical model using backpropagation"
      ]
    },
    {
      "metadata": {
        "id": "RnbV0wC9Q6Te",
        "colab_type": "code",
        "outputId": "99b2bf29-38d3-4911-8969-785f495c1f8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3489
        }
      },
      "cell_type": "code",
      "source": [
        "n_iteration = 100\n",
        "model.fit(x_train, y_train, batch_size=1000, epochs=n_iteration, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16000/16000 [==============================] - 0s 12us/sample - loss: 3.3263 - acc: 0.0324\n",
            "Epoch 2/100\n",
            "16000/16000 [==============================] - 0s 5us/sample - loss: 3.2129 - acc: 0.0322\n",
            "Epoch 3/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 3.1803 - acc: 0.0325\n",
            "Epoch 4/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 3.1488 - acc: 0.0329\n",
            "Epoch 5/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 3.1145 - acc: 0.0321\n",
            "Epoch 6/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 3.0776 - acc: 0.0324\n",
            "Epoch 7/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 3.0377 - acc: 0.0324\n",
            "Epoch 8/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 2.9946 - acc: 0.0324\n",
            "Epoch 9/100\n",
            "16000/16000 [==============================] - 0s 5us/sample - loss: 2.9465 - acc: 0.0325\n",
            "Epoch 10/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 2.8862 - acc: 0.0332\n",
            "Epoch 11/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 2.8048 - acc: 0.0434\n",
            "Epoch 12/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 2.6875 - acc: 0.1404\n",
            "Epoch 13/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 2.5373 - acc: 0.3100\n",
            "Epoch 14/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 2.4059 - acc: 0.3659\n",
            "Epoch 15/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 2.2891 - acc: 0.4059\n",
            "Epoch 16/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 2.1864 - acc: 0.4522\n",
            "Epoch 17/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 2.0968 - acc: 0.4852\n",
            "Epoch 18/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 2.0173 - acc: 0.5177\n",
            "Epoch 19/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.9472 - acc: 0.5428\n",
            "Epoch 20/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.8849 - acc: 0.5651\n",
            "Epoch 21/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.8300 - acc: 0.5831\n",
            "Epoch 22/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.7797 - acc: 0.5988\n",
            "Epoch 23/100\n",
            "16000/16000 [==============================] - 0s 5us/sample - loss: 1.7354 - acc: 0.6074\n",
            "Epoch 24/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.6948 - acc: 0.6234\n",
            "Epoch 25/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.6559 - acc: 0.6299\n",
            "Epoch 26/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.6218 - acc: 0.6386\n",
            "Epoch 27/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.5896 - acc: 0.6466\n",
            "Epoch 28/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.5594 - acc: 0.6482\n",
            "Epoch 29/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.5326 - acc: 0.6578\n",
            "Epoch 30/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.5072 - acc: 0.6586\n",
            "Epoch 31/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.4828 - acc: 0.6646\n",
            "Epoch 32/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.4602 - acc: 0.6724\n",
            "Epoch 33/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.4396 - acc: 0.6733\n",
            "Epoch 34/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.4182 - acc: 0.6812\n",
            "Epoch 35/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.4007 - acc: 0.6833\n",
            "Epoch 36/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.3823 - acc: 0.6843\n",
            "Epoch 37/100\n",
            "16000/16000 [==============================] - 0s 5us/sample - loss: 1.3661 - acc: 0.6867\n",
            "Epoch 38/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.3501 - acc: 0.6916\n",
            "Epoch 39/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.3359 - acc: 0.6923\n",
            "Epoch 40/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.3210 - acc: 0.6960\n",
            "Epoch 41/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.3068 - acc: 0.6963\n",
            "Epoch 42/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.2949 - acc: 0.6991\n",
            "Epoch 43/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.2817 - acc: 0.7024\n",
            "Epoch 44/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.2685 - acc: 0.7039\n",
            "Epoch 45/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.2595 - acc: 0.7071\n",
            "Epoch 46/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.2474 - acc: 0.7063\n",
            "Epoch 47/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.2377 - acc: 0.7065\n",
            "Epoch 48/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.2269 - acc: 0.7100\n",
            "Epoch 49/100\n",
            "16000/16000 [==============================] - 0s 5us/sample - loss: 1.2179 - acc: 0.7107\n",
            "Epoch 50/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.2078 - acc: 0.7145\n",
            "Epoch 51/100\n",
            "16000/16000 [==============================] - 0s 5us/sample - loss: 1.2002 - acc: 0.7122\n",
            "Epoch 52/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.1918 - acc: 0.7163\n",
            "Epoch 53/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.1828 - acc: 0.7194\n",
            "Epoch 54/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.1756 - acc: 0.7179\n",
            "Epoch 55/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.1679 - acc: 0.7224\n",
            "Epoch 56/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.1601 - acc: 0.7217\n",
            "Epoch 57/100\n",
            "16000/16000 [==============================] - 0s 5us/sample - loss: 1.1531 - acc: 0.7232\n",
            "Epoch 58/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.1454 - acc: 0.7247\n",
            "Epoch 59/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.1386 - acc: 0.7276\n",
            "Epoch 60/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.1316 - acc: 0.7271\n",
            "Epoch 61/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.1250 - acc: 0.7309\n",
            "Epoch 62/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.1188 - acc: 0.7303\n",
            "Epoch 63/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.1130 - acc: 0.7312\n",
            "Epoch 64/100\n",
            "16000/16000 [==============================] - 0s 5us/sample - loss: 1.1071 - acc: 0.7334\n",
            "Epoch 65/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.1011 - acc: 0.7359\n",
            "Epoch 66/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0952 - acc: 0.7343\n",
            "Epoch 67/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0905 - acc: 0.7374\n",
            "Epoch 68/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0858 - acc: 0.7352\n",
            "Epoch 69/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0799 - acc: 0.7386\n",
            "Epoch 70/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0759 - acc: 0.7399\n",
            "Epoch 71/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0709 - acc: 0.7386\n",
            "Epoch 72/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0671 - acc: 0.7391\n",
            "Epoch 73/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0614 - acc: 0.7410\n",
            "Epoch 74/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0570 - acc: 0.7424\n",
            "Epoch 75/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0515 - acc: 0.7431\n",
            "Epoch 76/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0491 - acc: 0.7429\n",
            "Epoch 77/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0443 - acc: 0.7456\n",
            "Epoch 78/100\n",
            "16000/16000 [==============================] - 0s 5us/sample - loss: 1.0400 - acc: 0.7460\n",
            "Epoch 79/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0355 - acc: 0.7463\n",
            "Epoch 80/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0310 - acc: 0.7476\n",
            "Epoch 81/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0272 - acc: 0.7494\n",
            "Epoch 82/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0247 - acc: 0.7483\n",
            "Epoch 83/100\n",
            "16000/16000 [==============================] - 0s 5us/sample - loss: 1.0204 - acc: 0.7483\n",
            "Epoch 84/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0164 - acc: 0.7515\n",
            "Epoch 85/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0141 - acc: 0.7526\n",
            "Epoch 86/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0111 - acc: 0.7491\n",
            "Epoch 87/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0079 - acc: 0.7509\n",
            "Epoch 88/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0035 - acc: 0.7519\n",
            "Epoch 89/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 1.0009 - acc: 0.7533\n",
            "Epoch 90/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 0.9979 - acc: 0.7564\n",
            "Epoch 91/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 0.9959 - acc: 0.7552\n",
            "Epoch 92/100\n",
            "16000/16000 [==============================] - 0s 5us/sample - loss: 0.9909 - acc: 0.7562\n",
            "Epoch 93/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 0.9894 - acc: 0.7563\n",
            "Epoch 94/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 0.9843 - acc: 0.7579\n",
            "Epoch 95/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 0.9820 - acc: 0.7579\n",
            "Epoch 96/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 0.9801 - acc: 0.7585\n",
            "Epoch 97/100\n",
            "16000/16000 [==============================] - 0s 5us/sample - loss: 0.9758 - acc: 0.7622\n",
            "Epoch 98/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 0.9731 - acc: 0.7577\n",
            "Epoch 99/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 0.9714 - acc: 0.7592\n",
            "Epoch 100/100\n",
            "16000/16000 [==============================] - 0s 4us/sample - loss: 0.9701 - acc: 0.7602\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f808c1e2a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "FLpRGVeCRMIw",
        "colab_type": "code",
        "outputId": "b77ff049-8d72-4ff1-92c2-21a3d1c09d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy: %f' %test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4000/4000 [==============================] - 0s 71us/sample - loss: 0.9906 - acc: 0.7545\n",
            "Test accuracy: 0.754500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iZOP3eXvSQmr",
        "colab_type": "code",
        "outputId": "3ff857e4-996a-4ad5-a3d3-03ba0f633192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "cell_type": "code",
      "source": [
        "# history. all losses\n",
        "all_loss = model.history.history['loss'] \n",
        "print(len(all_loss))\n",
        "\n",
        "# show the training errors\n",
        "plt.plot(np.squeeze(all_loss))\n",
        "plt.xlabel('iterations');plt.ylabel('cost')\n",
        "#plt.title('Learning rate %f' %learning_rate)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "HPIPp01OWQjm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#PSO Algorithm"
      ]
    },
    {
      "metadata": {
        "id": "OvdYJa47WOm2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fitness(str_costf,w):\n",
        "  model_nn.set_weights(w)\n",
        "  y_hat = model_nn.predict_on_batch(x_train)\n",
        "  if str_costf == 'LSE':\n",
        "    cost = np.linalg.norm(y_hat-y_train)**2/(y_train.shape[1]*x_train.shape[0])\n",
        "  elif str_costf == 'ABS':\n",
        "    cost = np.sum(np.abs(y_hat-y_train))/(y_train.shape[1]*x_train.shape[0])\n",
        "  return cost \n",
        "def gen_random_weights(NL):\n",
        "  w = list()\n",
        "  w_tmp = model_nn.get_weights()\n",
        "  for i in range(NL):\n",
        "    w.append(np.random.random_sample(w_tmp[i].shape)*0.8-0.4)\n",
        "  return w\n",
        "def list_subst(a,b):\n",
        "  # c=a-b\n",
        "  c=list()\n",
        "  for i in range(len(a)):\n",
        "    c.append(a[i]-b[i])\n",
        "  return c\n",
        "def list_mult(a,const):\n",
        "  # c=const*a\n",
        "  c=list()\n",
        "  for i in range(len(a)):\n",
        "    c.append(a[i]*const)\n",
        "  return c \n",
        "def list_add(*arglist):\n",
        "  # d=a+b+c\n",
        "  d=list()\n",
        "  if len(arglist)==2:\n",
        "    for i in range(len(arglist[0])):\n",
        "      d.append(arglist[0][i]+arglist[1][i])\n",
        "    return d  \n",
        "  if len(arglist)==3:\n",
        "    for i in range(len(arglist[0])):\n",
        "      d.append(arglist[0][i]+arglist[1][i]+arglist[2][i])\n",
        "    return d \n",
        "def list_limit(a,amin,amax):\n",
        "  c=list()\n",
        "  for i in range(len(a)):\n",
        "    c.append(np.clip(a[i],amin,amax))\n",
        "  return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7qNMLUZKWfQZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### PSO Algorithm\n",
        "NL=3\n",
        "model_nn = create_model(16,400,26)\n",
        "Nparticles = 1000\n",
        "Nepochs = 20\n",
        "# Create particles with random weigts matrix\n",
        "particles = list()\n",
        "vel_particles = list()\n",
        "for i in range(Nparticles):\n",
        "  particles.append(gen_random_weights(NL))\n",
        "  vel_particles.append(gen_random_weights(NL))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sIMDRbWcYFkg",
        "colab_type": "code",
        "outputId": "a62d3dc4-5d5c-4a21-f6c1-913b6a824628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "cell_type": "code",
      "source": [
        "c1=2;c2=2;w=1\n",
        "p_bestid = particles.copy()\n",
        "p_best = np.ones(Nparticles)*10\n",
        "g_bestid = list()\n",
        "g_best = 10\n",
        "cost = np.zeros(Nepochs)\n",
        "#w=np.linspace(2.0, 1.0, num=Nepochs)\n",
        "\n",
        "#Start trining\n",
        "for k in range(Nepochs):\n",
        "  #print(\"Epoch %2d of %2d , best cost = %% 5.2f\" %(k,Nepochs,))\n",
        "  for i in range(Nparticles):\n",
        "    fit = fitness('ABS',particles[i])\n",
        "    #print(fit)\n",
        "    if fit < p_best[i]:\n",
        "      p_best[i] = fit\n",
        "      p_bestid.insert(i,particles[i])\n",
        "  idx = np.argmin(p_best)\n",
        "  g_bestid = p_bestid[idx].copy()\n",
        "  #print(len(particles[0]))\n",
        "  for i in range(Nparticles):\n",
        "    r1=np.random.rand()\n",
        "    r2=np.random.rand()\n",
        "    p_delx = list_subst(p_bestid[i],particles[i])\n",
        "    g_delx = list_subst(g_bestid   ,particles[i])\n",
        "    inertia = list_mult(vel_particles[i],w)\n",
        "    cognitive = list_mult(p_delx,c1*r1)\n",
        "    social = list_mult(g_delx,c2*r2)\n",
        "    vid = list_add(inertia,cognitive,social)\n",
        "    xid = list_add(particles[i],vid)\n",
        "    vel_particles[i]=list_limit(vid,-1,1)\n",
        "    particles[i]=list_limit(xid,-1,1)\n",
        "  cost[k]=p_best[idx]\n",
        "  #if cost[k]==cost[k-1]):\n",
        "  #  w = w*0.9\n",
        "  #  print(w)\n",
        "  print(\"Epoch %2d of %2d , best cost = %8.6f\" %(k,Nepochs,cost[k]))\n",
        "model_nn.set_weights(g_bestid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0 of 20 , best cost = 0.278203\n",
            "Epoch  1 of 20 , best cost = 0.229827\n",
            "Epoch  2 of 20 , best cost = 0.165679\n",
            "Epoch  3 of 20 , best cost = 0.142845\n",
            "Epoch  4 of 20 , best cost = 0.142845\n",
            "Epoch  5 of 20 , best cost = 0.142845\n",
            "Epoch  6 of 20 , best cost = 0.142845\n",
            "Epoch  7 of 20 , best cost = 0.142845\n",
            "Epoch  8 of 20 , best cost = 0.142845\n",
            "Epoch  9 of 20 , best cost = 0.142845\n",
            "Epoch 10 of 20 , best cost = 0.136666\n",
            "Epoch 11 of 20 , best cost = 0.105996\n",
            "Epoch 12 of 20 , best cost = 0.096349\n",
            "Epoch 13 of 20 , best cost = 0.084517\n",
            "Epoch 14 of 20 , best cost = 0.082478\n",
            "Epoch 15 of 20 , best cost = 0.076090\n",
            "Epoch 16 of 20 , best cost = 0.072419\n",
            "Epoch 17 of 20 , best cost = 0.053876\n",
            "Epoch 18 of 20 , best cost = 0.046799\n",
            "Epoch 19 of 20 , best cost = 0.043485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EgYBWatXYWq2",
        "colab_type": "code",
        "outputId": "201cabb3-41ef-4b4e-d42c-f47cd441e5ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "model_nn.set_weights(g_bestid)\n",
        "test_loss, test_acc = model_nn.evaluate(x_test, y_test)\n",
        "print('Test accuracy: %f' %test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4000/4000 [==============================] - 0s 70us/sample - loss: 2.3412 - acc: 0.0335\n",
            "Test accuracy: 0.033500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p5nILJobYirT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}